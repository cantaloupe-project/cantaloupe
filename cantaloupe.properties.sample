###########################################################################
# Sample Cantaloupe configuration file
#
# Copy this file to `cantaloupe.properties` and edit as desired.
#
# Keys may change from version to version. See the "Upgrading" section of
# the website.
#
# Most changes will take effect without restarting. Those that won't are
# marked with "!!".
###########################################################################

# !! Leave blank to use the JVM default temporary directory.
temp_pathname =

# !! Configures the HTTP server. (Standalone mode only.)
http.enabled = true
http.host = 0.0.0.0
http.port = 8182

# !! Configures the HTTPS server. (Standalone mode only.)
https.enabled = false
https.host = 0.0.0.0
https.port = 8183

# !! Available values are `JKS` and `PKCS12`. (Standalone mode only.)
https.key_store_type = JKS
https.key_store_password = myPassword
https.key_store_path = /path/to/keystore.jks
https.key_password = myPassword

# !! Constrains the size of the web server's thread pool. Leave blank to
# use the defaults.
http.min_threads =
http.max_threads =

# !! Maximum size of the request queue. Leave blank to use the default.
http.accept_queue_limit =

# Base URI to use for internal links, such as Link headers and JSON-LD
# @id values, in a reverse-proxy context. This should only be used when
# X-Forwarded-* headers cannot be used instead. (See the user manual.)
base_uri =

# Normally, slashes in a URI path component must be percent-encoded as
# "%2F". If your proxy is not able to pass these through without decoding,
# you can define an alternate character or character sequence to substitute
# for a slash. Supply the non-percent-encoded version here, and use the
# percent-encoded version in URLs.
slash_substitute =

# Maximum number of pixels to return in a response, to prevent overloading
# the server. Requests for more pixels than this will receive an error
# response. Set to 0 for no maximum.
max_pixels = 10000000

# Maximum scale to allow (1.0 = full scale; 0 = no maximum).
max_scale = 1.0

# A meta-identifier is a superset of an identifier that includes other
# information like a page number and/or scale constraint. A meta-identifier
# transformer transforms a meta-identifier to and from a string in a URI
# path component.
# Available transformers include `StandardMetaIdentifierTransformer` and
# `DelegateMetaIdentifierTransformer`. See the user manual for more
# information about meta-identifiers and these options.
meta_identifier.transformer = StandardMetaIdentifierTransformer

# Character sequence that separates the components of a meta-identifier in
# the identifier portion of a URI.
meta_identifier.transformer.StandardMetaIdentifierTransformer.delimiter = ;

# If true, HTTP >= 400-level responses are logged at WARN and ERROR level.
# This may result in multiple log statements for the same error, but it may
# also help diagnose errors that have evaded logging.
log_error_responses = false

print_stack_trace_on_error_pages = true

###########################################################################
# DELEGATE SCRIPT
###########################################################################

# Enables the delegate script: a Ruby script containing various delegate
# methods. (See the user manual.)
delegate_script.enabled = false

# !! This can be an absolute path, or a filename; if only a filename is
# specified, it will be searched for in the same folder as this file, and
# then the current working directory.
delegate_script.pathname = delegates.rb

###########################################################################
# ENDPOINTS
###########################################################################

# Enables the IIIF Image API 1.x endpoint, at /iiif/1.
endpoint.iiif.1.enabled = false

# Enables the IIIF Image API 2.x endpoint, at /iiif/2.
endpoint.iiif.2.enabled = true

# Enables the IIIF Image API 3.x endpoint, at /iiif/3.
endpoint.iiif.3.enabled = true

# Minimum size that will be used in info.json `sizes` keys.
endpoint.iiif.min_size = 64

# Minimum size that will be used in info.json `tiles` keys. The user manual
# explains how these are calculated.
endpoint.iiif.min_tile_size = 512

# If true, requests for sizes other than those contained in an information
# response will be denied.
endpoint.iiif.restrict_to_sizes = false

# Enables the Control Panel, at /admin.
endpoint.admin.enabled = false
endpoint.admin.username = admin
endpoint.admin.secret =

# Enables the administrative HTTP API. (See the user manual.)
endpoint.api.enabled = false

# HTTP Basic credentials to access the HTTP API.
endpoint.api.username =
endpoint.api.secret =

# If true, sources and caches will be checked, resulting in a more robust
# but slower health check. Set this to false if these services already have
# their own health checks.
endpoint.health.dependency_check = false

###########################################################################
# SOURCES
###########################################################################

# Uses one source for all requests. Available values are `FilesystemSource`,
# `HttpSource`, `JdbcSource`, `S3Source`, and `AzureStorageSource`.
source.static = FilesystemSource

# If true, `source.static` will be overridden, and the `source()` delegate
# method will be used to select a source per-request.
source.delegate = false

#----------------------------------------
# FilesystemSource
#----------------------------------------

# How to look up files. Allowed values are `BasicLookupStrategy` and
# `ScriptLookupStrategy`. ScriptLookupStrategy uses the delegate script for
# dynamic lookups; see the user manual.
FilesystemSource.lookup_strategy = BasicLookupStrategy

# Server-side path that will be prefixed to the identifier in the URL.
# Trailing slash is important!
FilesystemSource.BasicLookupStrategy.path_prefix = /home/myself/images/

# Server-side path or extension that will be suffixed to the identifier in
# the URL.
FilesystemSource.BasicLookupStrategy.path_suffix =

#----------------------------------------
# HttpSource
#----------------------------------------

# Trusts insecure certificates and cipher suites.
HttpSource.allow_insecure = false

# Request timeout in seconds.
HttpSource.request_timeout =

# Tells HttpSource how to look up resources. Allowed values are
# `BasicLookupStrategy` and `ScriptLookupStrategy`. ScriptLookupStrategy
# uses a delegate method for dynamic lookups; see the user manual.
HttpSource.lookup_strategy = BasicLookupStrategy

# URL that will be prefixed to the identifier in the request URL.
# Trailing slash is important!
HttpSource.BasicLookupStrategy.url_prefix = http://localhost/images/

# Path, extension, query string, etc. that will be suffixed to the
# identifier in the request URL.
HttpSource.BasicLookupStrategy.url_suffix =

# Enables access to resources that require HTTP Basic authentication.
HttpSource.BasicLookupStrategy.auth.basic.username =
HttpSource.BasicLookupStrategy.auth.basic.secret =

# Read data in chunks when it may be more efficient. (This also may end up
# being less efficient, depending on many variables; see the user manual.)
HttpSource.chunking.enabled = true

# Chunk size.
HttpSource.chunking.chunk_size = 512K

# The per-request chunk cache caches downloaded chunks in memory during
# a request, and clears them when the request is complete.
HttpSource.chunking.cache.enabled = true

# Max per-request chunk cache size.
HttpSource.chunking.cache.max_size = 5M

# !! HTTP Proxy
# Enable HTTP Proxy for HttpSource
HttpSource.proxy.http.enabled = false
HttpSource.proxy.http.server = proxy.example.com
HttpSource.proxy.http.port = 8080

#----------------------------------------
# S3Source
#----------------------------------------

# !! Endpoint URI. Only needed for non-AWS endpoints.
S3Source.endpoint =

# !! AWS region. Only needed for AWS endpoints.
S3Source.region =

# !! Credentials for your AWS account.
# See: http://aws.amazon.com/security-credentials
# Note that this info can be obtained from elsewhere rather than setting
# it here; see the user manual.
S3Source.access_key_id =
S3Source.secret_key =

# How to look up objects. Allowed values are `BasicLookupStrategy` and
# `ScriptLookupStrategy`. ScriptLookupStrategy uses a delegate method for
# dynamic lookups; see the user manual.
S3Source.lookup_strategy = BasicLookupStrategy

# !! Name of the bucket containing images to be served.
S3Source.BasicLookupStrategy.bucket.name =

# Path within the bucket that will be prefixed to the identifier in the URL.
# Trailing slash is important!
S3Source.BasicLookupStrategy.path_prefix =

# Path or extension that will be suffixed to the identifier in the URL.
S3Source.BasicLookupStrategy.path_suffix =

# Read data in chunks when it may be more efficient. (This also may end up
# being less efficient, depending on many variables; see the user manual.)
S3Source.chunking.enabled = true

# Chunk size.
S3Source.chunking.chunk_size = 512K

# The per-request chunk cache caches downloaded chunks in memory during
# a request, and clears them when the request is complete.
S3Source.chunking.cache.enabled = true

# Max per-request chunk cache size.
S3Source.chunking.cache.max_size = 5M

#----------------------------------------
# AzureStorageSource
#----------------------------------------

# !! Name of your Azure account.
# Leave blank if using URI with a SAS token in your object key.
AzureStorageSource.account_name =

# !! Key of your Azure account.
# Leave blank if using URI with a SAS token in your object key.
AzureStorageSource.account_key =

# !! Name of the container containing images to be served.
# Leave blank if using URI with the container in your object key.
AzureStorageSource.container_name =

# Tells AzureStorageSource how to look up objects. Allowed values are
# `BasicLookupStrategy` and `ScriptLookupStrategy`. ScriptLookupStrategy
# uses a delegate method for dynamic lookups; see the user manual.
AzureStorageSource.lookup_strategy = BasicLookupStrategy

# Read data in chunks when it may be more efficient. (This also may end up
# being less efficient, depending on many variables; see the user manual.)
AzureStorageSource.chunking.enabled = true

# Chunk size.
AzureStorageSource.chunking.chunk_size = 512K

# The per-request chunk cache caches downloaded chunks in memory during
# a request, and clears them when the request is complete.
AzureStorageSource.chunking.cache.enabled = true

# Max per-request chunk cache size.
AzureStorageSource.chunking.cache.max_size = 5M

#----------------------------------------
# JdbcSource
#----------------------------------------

# Note: JdbcSource requires some delegate methods to be implemented in
# addition to the configuration here, and a JDBC driver to be installed on
# the classpath; see the user manual.

# !!
JdbcSource.url = jdbc:postgresql://localhost:5432/my_database
# !!
JdbcSource.user = postgres
# !!
JdbcSource.password = postgres

# !! Connection timeout in seconds.
JdbcSource.connection_timeout = 10

###########################################################################
# PROCESSORS
###########################################################################

#----------------------------------------
# Processor Selection
#----------------------------------------

# * If set to `AutomaticSelectionStrategy`, a "best" available processor
#   will be selected per-request based on formats and installed
#   dependencies.
# * If set to `ManualSelectionStrategy`, a processor will be chosen based
#   on the rest of the keys in this section.
processor.selection_strategy = AutomaticSelectionStrategy

# Built-in processors are `Java2dProcessor`, TurboJpegProcessor`,
# `KakaduNativeProcessor`, `OpenJpegProcessor`, `GrokProcessor`,`JaiProcessor`,
# `PdfBoxProcessor`, and `FfmpegProcessor`.
# Some of these have third-party dependencies and won't work out-of-the-box.

# These format-specific definitions are optional.
processor.ManualSelectionStrategy.avi = FfmpegProcessor
processor.ManualSelectionStrategy.bmp =
processor.ManualSelectionStrategy.flv = FfmpegProcessor
processor.ManualSelectionStrategy.gif =
processor.ManualSelectionStrategy.jp2 = KakaduNativeProcessor
processor.ManualSelectionStrategy.jpg =
processor.ManualSelectionStrategy.mov = FfmpegProcessor
processor.ManualSelectionStrategy.mp4 = FfmpegProcessor
processor.ManualSelectionStrategy.mpg = FfmpegProcessor
processor.ManualSelectionStrategy.pdf = PdfBoxProcessor
processor.ManualSelectionStrategy.png =
processor.ManualSelectionStrategy.tif =
processor.ManualSelectionStrategy.webm = FfmpegProcessor
processor.ManualSelectionStrategy.xpm =

# Fall back to this processor for any formats not assigned above.
processor.ManualSelectionStrategy.fallback = Java2dProcessor

#----------------------------------------
# Global Processor Configuration
#----------------------------------------

# Controls how content is fed to processors from stream-based sources.
# * `StreamStrategy` will try to stream a source image from a source when
#   possible, and use `processor.fallback_retrieval_strategy` otherwise.
# * `DownloadStrategy` will download it to a temporary file, and delete
#   it after the request is complete.
# * `CacheStrategy` will download it into the source cache using
#   FilesystemCache, which must also be configured. (This will perform a
#   lot better than DownloadStrategy if you can spare the disk space.)
processor.stream_retrieval_strategy = StreamStrategy

# Controls how an incompatible StreamSource + FileProcessor combination is
# dealt with.
# * `DownloadStrategy` and `CacheStrategy` work the same as above.
# * `AbortStrategy` causes the request to fail.
processor.fallback_retrieval_strategy = DownloadStrategy

# Resolution of vector rasterization (of e.g. PDFs) at a scale of 1.
processor.dpi = 150

# Color of the background when an image is rotated or alpha-flattened, for
# output formats that don't support transparency.
# This may not be respected for indexed color derivative images.
processor.background_color = white

# Available values are `bell`, `bspline`, `bicubic`, `box`, `hermite`,
# `lanczos3`, `mitchell`, `triangle`. (JaiProcessor & KakaduNativeProcessor
# ignore these.)
processor.downscale_filter = bicubic
processor.upscale_filter = bicubic

# If true, images are downscaled in a linear color space, which is more
# accurate. This only works with mono-resolution (non-pyramidal) images. It
# also may impair performance.
processor.downscale_linear = false

# Intensity of an unsharp mask from 0 to 1.
processor.sharpen = 0

# Progressive JPEGs are usually more compact.
processor.jpg.progressive = true

# JPEG output quality (1-100).
processor.jpg.quality = 80

# TIFF output compression type. Available values are `Deflate`, `JPEG`,
# `LZW`, and `RLE`. Leave blank for no compression.
processor.tif.compression = LZW

#----------------------------------------
# ImageIO Plugin Preferences
#----------------------------------------

# These override the default plugins used by the application and should not
# normally be changed.
processor.imageio.bmp.reader =
processor.imageio.gif.reader =
processor.imageio.gif.writer =
processor.imageio.jpg.reader =
processor.imageio.jpg.writer =
processor.imageio.png.reader =
processor.imageio.png.writer =
processor.imageio.tif.reader =
processor.imageio.tif.writer =
processor.imageio.xpm.reader =

#----------------------------------------
# FfmpegProcessor
#----------------------------------------

# Optional absolute path of the directory containing the FFmpeg binaries.
# Overrides the PATH.
FfmpegProcessor.path_to_binaries =

#----------------------------------------
# OpenJpegProcessor
#----------------------------------------

# Optional absolute path of the directory containing opj_decompress.
# Overrides the PATH.
OpenJpegProcessor.path_to_binaries =

#----------------------------------------
# GrokProcessor
#----------------------------------------

# Optional absolute path of the directory containing grk_decompress.
# Overrides the PATH.
GrokProcessor.path_to_binaries =

#----------------------------------------
# PdfBoxProcessor
#----------------------------------------

# The following will enable disk to be used as well as memory during
# PDF loading in PdfBoxProcessor.  If `max_memory_bytes` is -1 it
# will use unlimited memory.
processor.pdf.scratch_file_enabled = false
processor.pdf.max_memory_bytes = -1

###########################################################################
# CLIENT-SIDE CACHING
###########################################################################

# Whether to enable the response Cache-Control header.
cache.client.enabled = true

cache.client.max_age = 2592000
cache.client.shared_max_age =
cache.client.public = true
cache.client.private = false
cache.client.no_cache = false
cache.client.no_store = false
cache.client.must_revalidate = false
cache.client.proxy_revalidate = false
cache.client.no_transform = true

###########################################################################
# SERVER-SIDE CACHING
###########################################################################

# N.B.: The source cache may be used if the
# `processor.stream_retrieval_strategy` and/or
# `processor.fallback_retrieval_strategy` keys are set to `CacheStrategy`.

# FilesystemCache is the only available source cache.
cache.server.source = FilesystemCache

# Amount of time source cache content remains valid. Set to blank or 0
# for forever.
cache.server.source.ttl_seconds = 2592000

# Enables the derivative (processed image) cache.
cache.server.derivative.enabled = false

# Available values are `FilesystemCache`, `JdbcCache`, `RedisCache`,
# `HeapCache`, `S3Cache`, and `AzureStorageCache`.
cache.server.derivative =

# Amount of time derivative cache content remains valid. Set to blank or 0
# for forever.
cache.server.derivative.ttl_seconds = 2592000

# Whether to use the Java heap as a "level 1" cache for image infos, either
# independently or in front of a "level 2" derivative cache (if enabled).
cache.server.info.enabled = true

# If true, when a source reports that the requested source image has gone
# missing, all cached information relating to it (if any) will be deleted.
# (This is effectively always false when cache.server.resolve_first is also
# false.)
cache.server.purge_missing = false

# If true, the source image will be confirmed to exist before a cached copy
# is returned. If false, the cached copy will be returned without checking.
# Resolving first is safer but slower.
cache.server.resolve_first = false

# !! Enables the cache worker, which periodically purges invalid cache
# items in the background.
cache.server.worker.enabled = false

# !! The cache worker will wait this many seconds before starting its
# next shift.
cache.server.worker.interval = 86400

#----------------------------------------
# FilesystemCache
#----------------------------------------

# If this directory does not exist, it will be created automatically.
FilesystemCache.pathname = /var/cache/cantaloupe

# Levels of folder hierarchy in which to store cached images. Deeper depth
# results in fewer files per directory. Set to 0 to disable subdirectories.
# Purge the cache after changing this.
FilesystemCache.dir.depth = 3

# Number of characters in tree directory names. Should be set to
# 16^n < (max number of directory entries your filesystem can deal with).
# Purge the cache after changing this.
FilesystemCache.dir.name_length = 2

#----------------------------------------
# HeapCache
#----------------------------------------

# Target cache size, in bytes or a number ending in M, MB, G, GB, etc.
# This is not a hard limit, and may be transiently exceeded.
# Ensure your heap can accommodate this size.
HeapCache.target_size = 2G

# If true, the cache contents will be written to a file on exit and during
# cache worker shifts, and read back in at startup.
HeapCache.persist = false

# When the contents are persisted, this specifies the location of the cache
# file. If the parent directory does not exist, it will be created
# automatically.
HeapCache.persist.filesystem.pathname = /var/cache/cantaloupe/heap.cache

#----------------------------------------
# JdbcCache
#----------------------------------------

# !!
JdbcCache.url = jdbc:postgresql://localhost:5432/cantaloupe
# !!
JdbcCache.user = postgres
# !!
JdbcCache.password =

# !! Connection timeout in seconds.
JdbcCache.connection_timeout = 10

# These must be created manually; see the user manual.
JdbcCache.derivative_image_table = derivative_cache
JdbcCache.info_table = info_cache

#----------------------------------------
# S3Cache
#----------------------------------------

# !! Endpoint URI. Only needed for non-AWS endpoints.
S3Cache.endpoint =

# !! AWS region. Only needed for AWS endpoints.
S3Cache.region =

# !! Credentials for your AWS account.
# See: http://aws.amazon.com/security-credentials
# Note that this info can be obtained from elsewhere rather than setting it
# here; see the user manual.
S3Cache.access_key_id =
S3Cache.secret_key =

# !! Name of a bucket to use to hold cached data.
S3Cache.bucket.name =

# !! String that will be prefixed to object keys.
S3Cache.object_key_prefix =

#----------------------------------------
# AzureStorageCache
#----------------------------------------

# !! Credentials for your Azure account.
AzureStorageCache.account_name =
AzureStorageCache.account_key =

# !! Name of the container containing cached images.
AzureStorageCache.container_name =

# !! String that will be prefixed to object keys.
AzureStorageCache.object_key_prefix =

#----------------------------------------
# RedisCache
#----------------------------------------

# !! Redis connection info.
RedisCache.host = localhost
RedisCache.port = 6379
RedisCache.ssl = false
RedisCache.password =
RedisCache.database = 0

###########################################################################
# OVERLAYS
###########################################################################

# Controls how overlays are configured. `BasicStrategy` will use the
# `overlays.BasicStrategy.*` keys in this section. `ScriptStrategy` will
# use a delegate method. (See the user manual.)
overlays.strategy = BasicStrategy

# Whether to enable overlays using the BasicStrategy.
overlays.BasicStrategy.enabled = false

# `image` or `string`.
overlays.BasicStrategy.type = image

# Absolute path or URL of the overlay image. Must be a PNG file.
overlays.BasicStrategy.image = /path/to/overlay.png

# Overlay text.
overlays.BasicStrategy.string = Copyright © My Great Organization\nAll rights reserved.

# For a list of possible values, launch with the -list-fonts argument.
overlays.BasicStrategy.string.font = Helvetica

# Font size in points.
overlays.BasicStrategy.string.font.size = 24

# If the string doesn't fit in the image at the above size, the largest size
# at which it does fit will be used, down to this.
overlays.BasicStrategy.string.font.min_size = 18

# Font weight. 1 = regular, 2 = bold. Unfortunately, many fonts don't
# support fractional weights.
overlays.BasicStrategy.string.font.weight = 1.0

# Point spacing between glyphs, typically between -0.1 and 0.1.
overlays.BasicStrategy.string.glyph_spacing = 0.02

# CSS color syntax is supported.
overlays.BasicStrategy.string.color = white

# CSS color syntax is supported.
overlays.BasicStrategy.string.stroke.color = black

# Stroke width in pixels.
overlays.BasicStrategy.string.stroke.width = 1

# Color of a rectangular background to draw under the string.
# CSS color syntax and alpha are supported.
overlays.BasicStrategy.string.background.color = rgba(0, 0, 0, 100)

# Allowed values: `top left`, `top center`, `top right`, `left center`,
# `center`, `right center`, `bottom left`, `bottom center`, `bottom right`,
# `repeat` (images only), `scaled` (images only).
overlays.BasicStrategy.position = bottom right

# Pixel margin between the overlay and the image edge. Does not apply to
# `repeat` position.
overlays.BasicStrategy.inset = 10

# Output images less than this many pixels wide will not receive an overlay.
# Set to 0 to add the overlay regardless.
overlays.BasicStrategy.output_width_threshold = 400

# Output images less than this many pixels tall will not receive an overlay.
# Set to 0 to add the overlay regardless.
overlays.BasicStrategy.output_height_threshold = 300

###########################################################################
# LOGGING
###########################################################################

#----------------------------------------
# Application Log
#----------------------------------------

# `trace`, `debug`, `info`, `warn`, `error`, `all`, or `off`
log.application.level = debug

log.application.ConsoleAppender.enabled = true
log.application.ConsoleAppender.logstash.enabled = false

# N.B.: Don't enable FileAppender and RollingFileAppender simultaneously!
log.application.FileAppender.enabled = false
log.application.FileAppender.logstash.enabled = false
log.application.FileAppender.pathname = /path/to/logs/application.log

log.application.RollingFileAppender.enabled = false
log.application.RollingFileAppender.logstash.enabled = false
log.application.RollingFileAppender.pathname = /path/to/logs/application.log
log.application.RollingFileAppender.policy = TimeBasedRollingPolicy
log.application.RollingFileAppender.TimeBasedRollingPolicy.filename_pattern = /path/to/logs/application-%d{yyyy-MM-dd}.log
log.application.RollingFileAppender.TimeBasedRollingPolicy.max_history = 30

# See the "SyslogAppender" section for a list of facilities:
# http://logback.qos.ch/manual/appenders.html
log.application.SyslogAppender.enabled = false
log.application.SyslogAppender.host =
log.application.SyslogAppender.port = 514
log.application.SyslogAppender.facility = LOCAL0

#----------------------------------------
# Error Log
#----------------------------------------

# Application log messages with a severity of WARN or greater can be copied
# into a dedicated error log, which may make them easier to spot.

# N.B.: Don't enable FileAppender and RollingFileAppender simultaneously!
log.error.FileAppender.enabled = false
log.error.FileAppender.logstash.enabled = false
log.error.FileAppender.pathname = /path/to/logs/error.log

log.error.RollingFileAppender.enabled = false
log.error.RollingFileAppender.logstash.enabled = false
log.error.RollingFileAppender.pathname = /path/to/logs/error.log
log.error.RollingFileAppender.policy = TimeBasedRollingPolicy
log.error.RollingFileAppender.TimeBasedRollingPolicy.filename_pattern = /path/to/logs/error-%d{yyyy-MM-dd}.log
log.error.RollingFileAppender.TimeBasedRollingPolicy.max_history = 30

#----------------------------------------
# Access Log
#----------------------------------------

log.access.ConsoleAppender.enabled = false

# N.B.: Don't enable FileAppender and RollingFileAppender simultaneously!
log.access.FileAppender.enabled = false
log.access.FileAppender.pathname = /path/to/logs/access.log

# RollingFileAppender is an alternative to using something like
# FileAppender + logrotate.
log.access.RollingFileAppender.enabled = false
log.access.RollingFileAppender.pathname = /path/to/logs/access.log
log.access.RollingFileAppender.policy = TimeBasedRollingPolicy
log.access.RollingFileAppender.TimeBasedRollingPolicy.filename_pattern = /path/to/logs/access-%d{yyyy-MM-dd}.log
log.access.RollingFileAppender.TimeBasedRollingPolicy.max_history = 30

# See the "SyslogAppender" section for a list of facilities:
# http://logback.qos.ch/manual/appenders.html
log.access.SyslogAppender.enabled = false
log.access.SyslogAppender.host =
log.access.SyslogAppender.port = 514
log.access.SyslogAppender.facility = LOCAL0
